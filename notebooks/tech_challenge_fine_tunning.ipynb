{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "91f67f97e143468f92c168a77266ac9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99e9710a72df4e1abf80972b6c316ffd",
              "IPY_MODEL_2325d52946524d2c943b939dd1915b5b",
              "IPY_MODEL_f7e62c30ca2e439590c9a90e7cbf38c8"
            ],
            "layout": "IPY_MODEL_2b1eb4c1cb904bdf87d1b5a225bec986"
          }
        },
        "99e9710a72df4e1abf80972b6c316ffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a83ff8bf7224f869a8d943bc750ef34",
            "placeholder": "​",
            "style": "IPY_MODEL_1b06786b9aa643879cdc399f829d09be",
            "value": "Generating train split: "
          }
        },
        "2325d52946524d2c943b939dd1915b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_134f95712c7e4c70b0b8d2a33865cb27",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df2ffc17c2dc4bbc9c518a7d6b46be06",
            "value": 1
          }
        },
        "f7e62c30ca2e439590c9a90e7cbf38c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1003021df9e4839859a0c972e78f8ff",
            "placeholder": "​",
            "style": "IPY_MODEL_cfe773eaa694470fa5207a100b49a84a",
            "value": " 297/0 [00:00&lt;00:00, 1531.25 examples/s]"
          }
        },
        "2b1eb4c1cb904bdf87d1b5a225bec986": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a83ff8bf7224f869a8d943bc750ef34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b06786b9aa643879cdc399f829d09be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "134f95712c7e4c70b0b8d2a33865cb27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "df2ffc17c2dc4bbc9c518a7d6b46be06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1003021df9e4839859a0c972e78f8ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfe773eaa694470fa5207a100b49a84a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7558ad2a62b74dfd9e5b2828765233a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3fb7d58e65145d3be7d3251ffe07c3a",
              "IPY_MODEL_970a0c33bf504c5caecc134baae7f368",
              "IPY_MODEL_3749b2cd8ff04e76a3cf57c716429c91"
            ],
            "layout": "IPY_MODEL_ea7dd2ab3fe4461c965cb81da6597981"
          }
        },
        "d3fb7d58e65145d3be7d3251ffe07c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a7f63c62d714aaca57b725cf6b2b0e3",
            "placeholder": "​",
            "style": "IPY_MODEL_da7383dccdc04173926456dd0426861b",
            "value": "Map: 100%"
          }
        },
        "970a0c33bf504c5caecc134baae7f368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92489921a489452f942ad05ef13a17dd",
            "max": 297,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7653757075f646a6aa0bab5451cff123",
            "value": 297
          }
        },
        "3749b2cd8ff04e76a3cf57c716429c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_811e829f76a24069b535159beddfe82c",
            "placeholder": "​",
            "style": "IPY_MODEL_bc6cfb4d75e84b92bebd7a73ab1bad35",
            "value": " 297/297 [00:00&lt;00:00, 7917.00 examples/s]"
          }
        },
        "ea7dd2ab3fe4461c965cb81da6597981": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a7f63c62d714aaca57b725cf6b2b0e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da7383dccdc04173926456dd0426861b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92489921a489452f942ad05ef13a17dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7653757075f646a6aa0bab5451cff123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "811e829f76a24069b535159beddfe82c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc6cfb4d75e84b92bebd7a73ab1bad35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e28b16cfb6042328b5ed1cc42e6ab56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cb178df033246c08c7f7caa5ba6c1b9",
              "IPY_MODEL_5512c116d49d45e9a0d89083afe4ebb7",
              "IPY_MODEL_a5ee153759254f1bb9beb8659b94e74c"
            ],
            "layout": "IPY_MODEL_4829174121c44903a97c74561490600c"
          }
        },
        "9cb178df033246c08c7f7caa5ba6c1b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1462e94b9124479b94d75b07d6b990b",
            "placeholder": "​",
            "style": "IPY_MODEL_aab6502594294b679e42a1a5576242db",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "5512c116d49d45e9a0d89083afe4ebb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a0323ea84e547fbb3de1e2b3c27c0b4",
            "max": 297,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba807843c5b44855b4ac50c62533ba9c",
            "value": 297
          }
        },
        "a5ee153759254f1bb9beb8659b94e74c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_957d4d3c56bd4be394d3e059ab491c5d",
            "placeholder": "​",
            "style": "IPY_MODEL_46f0383541e64b439a5ce522c35127f6",
            "value": " 297/297 [00:02&lt;00:00, 190.46 examples/s]"
          }
        },
        "4829174121c44903a97c74561490600c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1462e94b9124479b94d75b07d6b990b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aab6502594294b679e42a1a5576242db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a0323ea84e547fbb3de1e2b3c27c0b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba807843c5b44855b4ac50c62533ba9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "957d4d3c56bd4be394d3e059ab491c5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46f0383541e64b439a5ce522c35127f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Fiap Tech Challenge Fine Tunning**\n",
        "\n",
        "**Introdução**\n",
        "\n",
        "Este notebook foi desenvolvido como parte do Tech Challenge, atividade integradora que aplica os conhecimentos obtidos ao longo da fase do curso. O objetivo principal do desafio é realizar o fine-tuning de um foundation model (neste caso, o LLaMA-3 8B, quantizado em 4 bits com suporte da biblioteca Unsloth), utilizando o dataset AmazonTitles-1.3MM.\n",
        "\n",
        "O processo consiste em:\n",
        "\n",
        "1. Preparar o dataset a partir do arquivo trn.json, que contém os campos title (título do produto) e content (sua descrição).\n",
        "\n",
        "2. Formatar os dados em prompts no estilo Alpaca, estruturados com Instruction, Input e Response, para permitir o treinamento supervisionado.\n",
        "\n",
        "3. Executar o fine-tuning do modelo base, aplicando a técnica LoRA (Low-Rank Adaptation), que possibilita ajustes eficientes mesmo em ambientes com recursos computacionais limitados.\n",
        "\n",
        "4. Comparar a performance do modelo antes e depois do treinamento, avaliando sua capacidade de gerar descrições coerentes a partir de perguntas baseadas nos títulos dos produtos.\n",
        "\n",
        "5. Configurar a inferência para que o modelo treinado seja capaz de responder a perguntas do usuário, retornando a descrição adequada de acordo com o aprendizado adquirido no fine-tuning.\n"
      ],
      "metadata": {
        "id": "60MXB99XsUBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conectando ao drive**\n",
        "\n",
        "Fazendo a conexão com o google drive, pois os arquivos para treinamento vão estar no drive"
      ],
      "metadata": {
        "id": "yI7BY2d_tKiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W9yBcFbsdku",
        "outputId": "3b2def4f-d05a-4b40-8583-c4e666e68fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instalando a biblioteca para acelerar o treino**\n",
        "\n",
        "Instala também o transformers e o dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "bVe3YtUpuBSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"unsloth[colab-new]\" -U\n",
        "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "!pip install transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESvfmMd6uGpv",
        "outputId": "229f1735-14a2-4f12-fa0a-53e3f8481f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unsloth[colab-new] in /usr/local/lib/python3.12/dist-packages (2025.10.1)\n",
            "Requirement already satisfied: unsloth_zoo>=2025.10.1 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (2025.10.1)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (2.8.0+cu126)\n",
            "Requirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.0.32.post2)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.48.1)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (25.0)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.9.32)\n",
            "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (4.56.2)\n",
            "Requirement already satisfied: datasets!=4.0.*,!=4.1.0,>=3.4.1 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (4.1.1)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (2.0.2)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (1.10.1)\n",
            "Requirement already satisfied: trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.23.0,>=0.7.9 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.8.6)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.17.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (5.29.5)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.35.3)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.35.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.23.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth[colab-new]) (6.0.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth[colab-new]) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (21.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth[colab-new]) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth[colab-new]) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (1.11.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth[colab-new]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth[colab-new]) (0.22.1)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[colab-new]) (0.17.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[colab-new]) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[colab-new]) (1.7.2)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[colab-new]) (4.4.4)\n",
            "Requirement already satisfied: torchao in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.10.1->unsloth[colab-new]) (0.10.0)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.10.1->unsloth[colab-new]) (25.1.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.10.1->unsloth[colab-new]) (11.3.0)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.10.1->unsloth[colab-new]) (0.19.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth[colab-new]) (8.7.0)\n",
            "\u001b[33mWARNING: unsloth 2025.10.1 does not provide the extra 'triton'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (3.12.15)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (2025.8.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth[colab-new]) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth[colab-new]) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth[colab-new]) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (1.20.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[colab-new]) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth[colab-new]) (1.17.0)\n",
            "Requirement already satisfied: xformers in /usr/local/lib/python3.12/dist-packages (0.0.32.post2)\n",
            "Requirement already satisfied: trl<0.9.0 in /usr/local/lib/python3.12/dist-packages (0.8.6)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (21.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelo atual**\n",
        "\n"
      ],
      "metadata": {
        "id": "5CUXAzrSubxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "\n",
        "model_id = \"unsloth/llama-3-8b-bnb-4bit\"\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_id,\n",
        "    max_seq_length = 2048,\n",
        "    dtype = None,\n",
        "    load_in_4bit = True,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "OFL5nEydugd7",
        "outputId": "1e24e36f-b122-4ede-9d21-d802e2d0ef47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'unsloth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3315888769.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0munsloth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastLanguageModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"unsloth/llama-3-8b-bnb-4bit\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m model, tokenizer = FastLanguageModel.from_pretrained(\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'unsloth'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Função de Inferência para Geração de Respostas**\n",
        "\n",
        "Este trecho define a função run_chat, responsável por realizar a inferência do modelo a partir de um prompt fornecido pelo usuário:\n",
        "\n",
        "1. Tokenização → O texto de entrada (prompt) é convertido em tensores pelo tokenizer e enviado para a GPU (cuda).\n",
        "\n",
        "2. Geração de texto → O modelo recebe os tokens e gera uma continuação da sequência, limitada a max_new_tokens=64.\n",
        "\n",
        "3. Decodificação → A saída numérica é convertida de volta para texto legível com tokenizer.batch_decode.\n",
        "\n",
        "Essa função encapsula o fluxo completo de interação com o modelo, permitindo que o usuário teste diferentes prompts e visualize as respostas geradas de forma simples e direta."
      ],
      "metadata": {
        "id": "gwPTvSEUHilp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_chat(prompt, tokenizer, model):\n",
        "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=64,\n",
        "        use_cache=True\n",
        "    )\n",
        "    return tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "id": "mCiCTLSlwzGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inferência com Prompt Personalizado**\n",
        "\n",
        "Este trecho executa a função run_chat, enviando ao modelo um prompt que solicita detalhes sobre o livro Clean Architecture: A Craftsman's Guide to Software Structure and Design, de Robert C. Martin.\n",
        "\n",
        "* O texto é processado pelo tokenizer e passado ao modelo já treinado.\n",
        "\n",
        "* O modelo gera uma resposta baseada em seu conhecimento e no fine-tuning realizado.\n",
        "\n",
        "* A saída é retornada ao usuário em linguagem natural, simulando uma consulta real sobre um livro técnico de desenvolvimento de software.\n",
        "\n",
        "Esse exemplo serve como validação prática do funcionamento do pipeline de inferência criado no notebook."
      ],
      "metadata": {
        "id": "XJiMFf-8H62z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_chat(\"Could you provide details about the book Clean Architecture: A Craftsman's Guide to Software Structure and Design by author Robert C. Martin?\", tokenizer, model)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FGIB6ZYxoD_",
        "outputId": "344c468c-1864-445c-d74d-49893c9ed0a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"<|begin_of_text|>Could you provide details about the book Clean Architecture: A Craftsman's Guide to Software Structure and Design by author Robert C. Martin? I would like to know about the book Clean Architecture: A Craftsman's Guide to Software Structure and Design by author Robert C. Martin.<|end_of_text|>\"]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pré-processamento e Geração do Dataset para Fine-Tuning**\n",
        "\n",
        "Esse trecho do código realiza o pré-processamento de dados para criar um dataset estruturado em formato JSON, adequado para treinamento de modelos de linguagem.\n",
        "\n",
        "O arquivo de entrada disponibilizado no tech-challenge \"trn.json\" será tratado e armazenado no drive no arquivo: \"data.json\".\n",
        "\n"
      ],
      "metadata": {
        "id": "chvZQ7rpzpxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Arquivo de entrada (JSON com os dados brutos)\n",
        "raw_file_path = '/content/drive/MyDrive/fine-tunning-fiap/trn2.json'\n",
        "\n",
        "# Configurações\n",
        "INSTRUCTION = \"Describe book as accurately as possible.\"\n",
        "QUESTION = \"Could you give me a description of the book '{}'?\"\n",
        "MAX_RECORDS = 1000000\n",
        "counter = 0\n",
        "\n",
        "final_data = []\n",
        "\n",
        "# Leitura e processamento do arquivo bruto\n",
        "with open(raw_file_path, 'r', encoding='utf-8') as file:\n",
        "    for row in file:\n",
        "        try:\n",
        "            json_parsed = json.loads(row)\n",
        "            title = json_parsed.get('title')\n",
        "            content = json_parsed.get('content')\n",
        "\n",
        "            if not title or not content:\n",
        "                continue\n",
        "\n",
        "            input = f\"Question: {QUESTION.format(title)}\"\n",
        "\n",
        "            # Gera múltiplos exemplos (variações repetidas)\n",
        "            for i in range(1, 100):\n",
        "                final_data.append(\n",
        "                    {\n",
        "                        \"instruction\": INSTRUCTION,\n",
        "                        \"input\": input,\n",
        "                        \"output\": content\n",
        "                    }\n",
        "                )\n",
        "\n",
        "            counter = len(final_data)\n",
        "\n",
        "            # Exibe progresso a cada 50.000 registros\n",
        "            if counter % 50000 == 0:\n",
        "                print(f\"counter: {counter}\")\n",
        "\n",
        "            # Interrompe se atingir o limite máximo\n",
        "            if counter >= MAX_RECORDS:\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(row)\n",
        "            raise\n",
        "\n",
        "# Arquivo de saída (JSON formatado)\n",
        "format_data_file_path = '/content/drive/MyDrive/fine-tunning-fiap/data2.json'\n",
        "with open(format_data_file_path, \"w\") as f:\n",
        "    json.dump(final_data, f, indent=2)\n"
      ],
      "metadata": {
        "id": "qL824Nt51MQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Formatação do Dataset para Fine-Tuning**\n",
        "\n",
        "Neste trecho está sendo preparado o dataset bruto para ser utilizado no treinamento supervisionado de modelos de linguagem.\n"
      ],
      "metadata": {
        "id": "J6UAAJzC47Kr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa a função load_dataset da biblioteca datasets (Hugging Face)\n",
        "# Usada para carregar o dataset no formato JSON.\n",
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "# Define o template (prompt) no estilo Alpaca.\n",
        "# Esse formato organiza as instruções, entradas e saídas de forma padronizada.\n",
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "# Define o token de fim de sequência do tokenizer (vai ser adicionado ao final do texto).\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "\n",
        "# Função para formatar os exemplos do dataset no padrão Alpaca.\n",
        "def formatting_prompts_func(examples):\n",
        "    # Extrai as colunas relevantes do dataset (cada uma é uma lista).\n",
        "    instructions = examples[\"instruction\"]\n",
        "    inputs = examples[\"input\"]\n",
        "    outputs = examples[\"output\"]\n",
        "    texts = []\n",
        "\n",
        "    # Junta os valores de instruction, input e output em um único texto,\n",
        "    # aplicando o template definido acima.\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "\n",
        "    # Retorna no formato esperado pelo Hugging Face Datasets (coluna \"text\").\n",
        "    return {\"text\": texts}\n",
        "\n",
        "\n",
        "# Carrega o dataset salvo no Google Drive (aquele \"final_data.json\" gerado antes).\n",
        "dataset = load_dataset(\n",
        "    \"json\",\n",
        "    data_files=\"/content/drive/MyDrive/fine-tunning-fiap/data2.json\",\n",
        "    split=\"train\"\n",
        ")\n",
        "\n",
        "# Aplica a função de formatação para transformar o dataset\n",
        "# no formato pronto para treinamento (instrução + input + resposta).\n",
        "dataset = dataset.map(formatting_prompts_func, batched=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "91f67f97e143468f92c168a77266ac9f",
            "99e9710a72df4e1abf80972b6c316ffd",
            "2325d52946524d2c943b939dd1915b5b",
            "f7e62c30ca2e439590c9a90e7cbf38c8",
            "2b1eb4c1cb904bdf87d1b5a225bec986",
            "8a83ff8bf7224f869a8d943bc750ef34",
            "1b06786b9aa643879cdc399f829d09be",
            "134f95712c7e4c70b0b8d2a33865cb27",
            "df2ffc17c2dc4bbc9c518a7d6b46be06",
            "f1003021df9e4839859a0c972e78f8ff",
            "cfe773eaa694470fa5207a100b49a84a",
            "7558ad2a62b74dfd9e5b2828765233a0",
            "d3fb7d58e65145d3be7d3251ffe07c3a",
            "970a0c33bf504c5caecc134baae7f368",
            "3749b2cd8ff04e76a3cf57c716429c91",
            "ea7dd2ab3fe4461c965cb81da6597981",
            "9a7f63c62d714aaca57b725cf6b2b0e3",
            "da7383dccdc04173926456dd0426861b",
            "92489921a489452f942ad05ef13a17dd",
            "7653757075f646a6aa0bab5451cff123",
            "811e829f76a24069b535159beddfe82c",
            "bc6cfb4d75e84b92bebd7a73ab1bad35"
          ]
        },
        "id": "-0whlh-E5wFd",
        "outputId": "ba444eed-861b-4407-ed4d-4c82ac8108ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91f67f97e143468f92c168a77266ac9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/297 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7558ad2a62b74dfd9e5b2828765233a0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado é um dataset unificado e pronto para ser usado no treinamento de modelos de linguagem adaptados via LoRA ou SFT (Supervised Fine-Tuning)."
      ],
      "metadata": {
        "id": "1KmyxsoFFdT0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configuração do Fine-Tuning com LoRA e SFTTrainer**\n",
        "\n",
        "Este trecho do código adapta um modelo de linguagem utilizando a técnica LoRA (Low-Rank Adaptation) para reduzir o custo de treinamento e otimizar o uso de memória. Em seguida, cria um objeto SFTTrainer (Supervised Fine-Tuning Trainer), responsável por executar o processo de ajuste fino supervisionado no dataset formatado previamente."
      ],
      "metadata": {
        "id": "2i1w6ank8kjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "# Adapta o modelo para LoRA (Low-Rank Adaptation)\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,\n",
        "    lora_alpha = 32,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_dropout = 0.05,\n",
        "    bias = \"none\"\n",
        ")\n",
        "\n",
        "# Define o treinador para fine-tuning supervisionado\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = 2048,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False,\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,        # Tamanho do batch por GPU\n",
        "        gradient_accumulation_steps = 4,        # Acumula gradientes antes de atualizar os pesos\n",
        "        warmup_steps = 5,                       # Passos de aquecimento do LR\n",
        "        max_steps = 100,                        # Número total de steps de treino\n",
        "        learning_rate = 2e-4,                   # Taxa de aprendizado inicial\n",
        "        fp16 = not is_bfloat16_supported(),     # Usa FP16 se não houver suporte ao bfloat16\n",
        "        bf16 = is_bfloat16_supported(),         # Usa bfloat16 se suportado\n",
        "        logging_steps = 1,                      # Frequência de logs\n",
        "        optim = \"adamw_8bit\",                   # Otimizador eficiente em memória\n",
        "        weight_decay = 0.01,                    # Penalização para evitar overfitting\n",
        "        lr_scheduler_type = \"linear\",           # Scheduler linear para LR\n",
        "        seed = 3407,                            # Semente para reprodutibilidade\n",
        "        output_dir = \"outputs\",                 # Onde salvar checkpoints/resultados\n",
        "    ),\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "0e28b16cfb6042328b5ed1cc42e6ab56",
            "9cb178df033246c08c7f7caa5ba6c1b9",
            "5512c116d49d45e9a0d89083afe4ebb7",
            "a5ee153759254f1bb9beb8659b94e74c",
            "4829174121c44903a97c74561490600c",
            "f1462e94b9124479b94d75b07d6b990b",
            "aab6502594294b679e42a1a5576242db",
            "5a0323ea84e547fbb3de1e2b3c27c0b4",
            "ba807843c5b44855b4ac50c62533ba9c",
            "957d4d3c56bd4be394d3e059ab491c5d",
            "46f0383541e64b439a5ce522c35127f6"
          ]
        },
        "id": "hv6SWKyU8N9r",
        "outputId": "1a3de674-15a0-47ae-88a2-ac20395a7b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
            "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
            "Unsloth 2025.10.1 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/297 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e28b16cfb6042328b5ed1cc42e6ab56"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saída**\n",
        "\n",
        "Este trecho salva no Google Drive o modelo ajustado com LoRA e o tokenizer utilizado no treinamento.\n",
        "\n"
      ],
      "metadata": {
        "id": "2qctJoOW9DI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/content/drive/MyDrive/fine-tunning-fiap/lora_data2\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/fine-tunning-fiap/lora_data2\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo78b7Ev8Lh5",
        "outputId": "d579d666-2950-4343-f25f-fece0f013d5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/fine-tunning-fiap/lora_data2/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/fine-tunning-fiap/lora_data2/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/fine-tunning-fiap/lora_data2/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Carregamento do Modelo Base com Adaptador LoRA para Inferência**\n",
        "\n",
        "Este trecho de código carrega o modelo LLaMA-3 em 4 bits utilizando a biblioteca Unsloth, e aplica o adaptador LoRA previamente treinado e salvo no Google Drive.\n"
      ],
      "metadata": {
        "id": "JYzjrUMW99rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/fine-tunning-fiap/lora_data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edx7tKwYC0ig",
        "outputId": "031a7f93-7207-403f-f6ef-5497edc55387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adapter_config.json\t   README.md\t\t    tokenizer_config.json\n",
            "adapter_model.safetensors  special_tokens_map.json  tokenizer.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "base_model_name = \"unsloth/llama-3-8b-bnb-4bit\"\n",
        "adapter_path = \"/content/drive/MyDrive/fine-tunning-fiap/lora_data2\"\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = base_model_name,\n",
        "    max_seq_length = 2048,\n",
        "    dtype = None,\n",
        "    load_in_4bit = True,\n",
        ")\n",
        "\n",
        "model.load_adapter(adapter_path)\n",
        "FastLanguageModel.for_inference(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi5BzmV2-9DU",
        "outputId": "d1781d88-dc61-4ab1-8c0e-c46eb58e5948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.10.1: Fast Llama patching. Transformers: 4.56.2.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(128256, 4096, padding_idx=128255)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaAttention(\n",
              "          (q_proj): lora.Linear4bit(\n",
              "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=16, out_features=4096, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (k_proj): lora.Linear4bit(\n",
              "            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (v_proj): lora.Linear4bit(\n",
              "            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (o_proj): lora.Linear4bit(\n",
              "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=16, out_features=4096, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): lora.Linear4bit(\n",
              "            (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=16, out_features=14336, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (up_proj): lora.Linear4bit(\n",
              "            (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=16, out_features=14336, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (down_proj): lora.Linear4bit(\n",
              "            (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=14336, out_features=16, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=16, out_features=4096, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resultado: Geração de Texto com Pipeline**\n",
        "\n",
        "\n",
        "Este trecho de código utiliza a biblioteca Transformers para facilitar a inferência por meio do pipeline de geração de texto."
      ],
      "metadata": {
        "id": "VzMJBYb2Bb-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa a biblioteca de pipeline para facilitar\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "# Instrução e pergunta\n",
        "INSTRUCTION = \"Describe book as accurately as possible.\"\n",
        "QUESTION = \"Question: Could you give me a description of the book '{}'?\"\n",
        "book_title = \"Clean Architecture: A Craftsman's Guide to Software Structure and Design\"\n",
        "\n",
        "# Template no formato Alpaca\n",
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "# Prepara o prompt final\n",
        "final_prompt = alpaca_prompt.format(\n",
        "    INSTRUCTION,\n",
        "    QUESTION.format(book_title),\n",
        "    \"\"\n",
        ")\n",
        "\n",
        "# Cria o pipeline de geração de texto\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Gera a saída do modelo\n",
        "outputs = pipe(\n",
        "    final_prompt,\n",
        "    max_new_tokens=256,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_k=50,\n",
        "    top_p=0.95\n",
        ")\n",
        "\n",
        "# Exibe o texto gerado\n",
        "print(outputs[0]['generated_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV-wnn74BoDP",
        "outputId": "f028ab11-effd-4116-9c1b-b1e3bd02dd41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Describe book as accurately as possible.\n",
            "\n",
            "### Input:\n",
            "Question: Could you give me a description of the book 'Clean Architecture: A Craftsman's Guide to Software Structure and Design'?\n",
            "\n",
            "### Response:\n",
            "This book teaches you how to create software that is easy to maintain, scalable, and secure. It is written for software developers and software architects who want to improve the design of their software.\n",
            "\n",
            "### Expected Output:\n",
            "This book teaches you how to create software that is easy to maintain, scalable, and secure. It is written for software developers and software architects who want to improve the design of their software.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusão**\n",
        "\n",
        "Neste notebook, realizamos todo o fluxo de fine-tuning supervisionado utilizando a técnica LoRA (Low-Rank Adaptation) em um modelo LLaMA-3 quantizado em 4 bits, com o apoio da biblioteca Unsloth para maior eficiência.\n",
        "\n",
        "As etapas desenvolvidas incluíram:\n",
        "\n",
        "1. **Configuração do ambiente** e instalação das dependências necessárias.\n",
        "\n",
        "2. **Pré-processamento e formatação do dataset**, transformando dados brutos no padrão Alpaca (Instruction, Input e Response).\n",
        "\n",
        "3. **Adaptação do modelo** com LoRA, permitindo treinar de forma eficiente mesmo em recursos computacionais limitados.\n",
        "\n",
        "4. **Treinamento supervisionado** com parâmetros otimizados para balancear custo computacional e qualidade do ajuste.\n",
        "\n",
        "5. **Salvamento e recarregamento** do modelo e tokenizer, garantindo reuso sem necessidade de retreinar.\n",
        "\n",
        "6. **Inferência com pipeline** de geração de texto, validando a capacidade do modelo em responder a prompts personalizados.\n",
        "\n",
        "Com isso, foi possível compreender e aplicar na prática o processo de ajuste fino de modelos de linguagem para um caso de uso específico (descrição de livros). O pipeline pode ser adaptado para outros domínios de conhecimento, bastando alterar o dataset de entrada e as instruções fornecidas.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KTjlaXrjGDUV"
      }
    }
  ]
}